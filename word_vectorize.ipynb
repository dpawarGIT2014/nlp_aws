{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data Input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-us-east-1-023375022819\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import json\n",
    "import boto3\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "role = get_execution_role()\n",
    "#print(role) # This is the role that SageMaker would use to leverage AWS resources (S3, CloudWatch) on your behalf\n",
    "\n",
    "bucket = sess.default_bucket() # Replace with your own bucket name if needed\n",
    "print(bucket)\n",
    "prefix = 'NLP_AWS/NLP_AWS' #Replace with the prefix under which you want to store the data if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-08-28 02:25:12--  https://s3.amazonaws.com/fast-ai-nlp/amazon_review_polarity_csv.tgz\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.205.133\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.205.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 688339454 (656M) [application/x-tar]\n",
      "Saving to: ‘amazon_review_polarity_csv.tgz.2’\n",
      "\n",
      "amazon_review_polar 100%[===================>] 656.45M  52.5MB/s    in 14s     \n",
      "\n",
      "2019-08-28 02:25:26 (46.9 MB/s) - ‘amazon_review_polarity_csv.tgz.2’ saved [688339454/688339454]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://s3.amazonaws.com/fast-ai-nlp/amazon_review_polarity_csv.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amazon_review_polarity_csv/\n",
      "amazon_review_polarity_csv/train.csv\n",
      "amazon_review_polarity_csv/readme.txt\n",
      "amazon_review_polarity_csv/test.csv\n"
     ]
    }
   ],
   "source": [
    "!tar -xzvf amazon_review_polarity_csv.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"2\",\"Stuning even for the non-gamer\",\"This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^\"\r\n",
      "\"2\",\"The best soundtrack ever to anything.\",\"I'm reading a lot of reviews saying that this is the best 'game soundtrack' and I figured that I'd write a review to disagree a bit. This in my opinino is Yasunori Mitsuda's ultimate masterpiece. The music is timeless and I'm been listening to it for years now and its beauty simply refuses to fade.The price tag on this is pretty staggering I must say, but if you are going to buy any cd for this much money, this is the only one that I feel would be worth every penny.\"\r\n",
      "\"2\",\"Amazing!\",\"This soundtrack is my favorite music of all time, hands down. The intense sadness of \"\"Prisoners of Fate\"\" (which means all the more if you've played the game) and the hope in \"\"A Distant Promise\"\" and \"\"Girl who Stole the Star\"\" have been an important inspiration to me personally throughout my teen years. The higher energy tracks like \"\"Chrono Cross ~ Time's Scar~\"\", \"\"Time of the Dreamwatch\"\", and \"\"Chronomantique\"\" (indefinably remeniscent of Chrono Trigger) are all absolutely superb as well.This soundtrack is amazing music, probably the best of this composer's work (I haven't heard the Xenogears soundtrack, so I can't say for sure), and even if you've never played the game, it would be worth twice the price to buy it.I wish I could give it 6 stars.\"\r\n"
     ]
    }
   ],
   "source": [
    "!head amazon_review_polarity_csv/train.csv -n 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Then upload file from sagemaker folder to S3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.7 s, sys: 6.89 s, total: 19.6 s\n",
      "Wall time: 18.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_channel = prefix + '/train'\n",
    "test_channel = prefix + '/test'\n",
    "\n",
    "sess.upload_data(path='amazon_review_polarity_csv/train.csv', bucket=bucket, key_prefix=train_channel)\n",
    "sess.upload_data(path='amazon_review_polarity_csv/test.csv', bucket=bucket, key_prefix=test_channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read datafile as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"s3://sagemaker-us-east-1-023375022819/NLP_AWS/NLP_AWS/train/train.csv\", names=[\"Label\", \"Title\", \"Review\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_df = df[df['Label'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>Buyer beware</td>\n",
       "      <td>This is a self-published book, and if you want...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>The Worst!</td>\n",
       "      <td>A complete waste of time. Typographical errors...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>Oh please</td>\n",
       "      <td>I guess you have to be a romance novel lover f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>Awful beyond belief!</td>\n",
       "      <td>I feel I have to write to keep others from was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>Don't try to fool us with fake reviews.</td>\n",
       "      <td>It's glaringly obvious that all of the glowing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Label                                    Title  \\\n",
       "6       1                             Buyer beware   \n",
       "10      1                               The Worst!   \n",
       "13      1                                Oh please   \n",
       "14      1                     Awful beyond belief!   \n",
       "15      1  Don't try to fool us with fake reviews.   \n",
       "\n",
       "                                               Review  \n",
       "6   This is a self-published book, and if you want...  \n",
       "10  A complete waste of time. Typographical errors...  \n",
       "13  I guess you have to be a romance novel lover f...  \n",
       "14  I feel I have to write to keep others from was...  \n",
       "15  It's glaringly obvious that all of the glowing...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1800000 entries, 6 to 3599998\n",
      "Data columns (total 3 columns):\n",
      "Label     int64\n",
      "Title     object\n",
      "Review    object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 54.9+ MB\n"
     ]
    }
   ],
   "source": [
    "neg_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_df = neg_df.iloc[:,0:10000]['Review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6     This is a self-published book, and if you want...\n",
       "10    A complete waste of time. Typographical errors...\n",
       "13    I guess you have to be a romance novel lover f...\n",
       "14    I feel I have to write to keep others from was...\n",
       "15    It's glaringly obvious that all of the glowing...\n",
       "19    sizes are much smaller than what is recomended...\n",
       "20    This model may be ok for sedentary types, but ...\n",
       "22    Rather than scratches and insect droppings, th...\n",
       "25    I have had the charger for more than two years...\n",
       "26    I bought one of these chargers..the instructio...\n",
       "Name: Review, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1800000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/ipykernel/__main__.py:1: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "extract_df.to_csv('extract_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comprehend_channel = prefix + '/comprehend'\n",
    "\n",
    "sess.upload_data(path='extract_df.csv', bucket=bucket, key_prefix=comprehend_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-08-28 15:31:17--  https://s3.console.aws.amazon.com/s3/object/sagemaker-us-east-1-023375022819/NLP_AWS/NLP_AWS/023375022819-TOPICS-f0b9b40086d3cc882f48800be187f3fb/output/output.tar.gz\n",
      "Resolving s3.console.aws.amazon.com (s3.console.aws.amazon.com)... 54.239.31.91\n",
      "Connecting to s3.console.aws.amazon.com (s3.console.aws.amazon.com)|54.239.31.91|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 989 [text/html]\n",
      "Saving to: ‘output.tar.gz’\n",
      "\n",
      "output.tar.gz       100%[===================>]     989  --.-KB/s    in 0s      \n",
      "\n",
      "2019-08-28 15:31:17 (135 MB/s) - ‘output.tar.gz’ saved [989/989]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://s3.console.aws.amazon.com/s3/object/sagemaker-us-east-1-023375022819/NLP_AWS/NLP_AWS/023375022819-TOPICS-f0b9b40086d3cc882f48800be187f3fb/output/output.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 68.0 KiB/68.0 KiB (424.7 KiB/s) with 1 file(s) remaining\r",
      "download: s3://sagemaker-us-east-1-023375022819/NLP_AWS/NLP_AWS/023375022819-TOPICS-f0b9b40086d3cc882f48800be187f3fb/output/output.tar.gz to ./output.tar.gz\r\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp s3://sagemaker-us-east-1-023375022819/NLP_AWS/NLP_AWS/023375022819-TOPICS-f0b9b40086d3cc882f48800be187f3fb/output/output.tar.gz ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic-terms.csv\r\n",
      "doc-topics.csv\r\n"
     ]
    }
   ],
   "source": [
    "!tar -xvzf output.tar.gz   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic,term,weight\r\n",
      "000,item,0.01320014\r\n",
      "000,price,0.009271662\r\n",
      "000,cheap,0.008077917\r\n",
      "000,product,0.0145492125\r\n",
      "000,return,0.00996442\r\n",
      "000,buy,0.022574656\r\n",
      "000,worth,0.0070977435\r\n",
      "000,pay,0.005717317\r\n",
      "000,wear,0.0050701024\r\n",
      "000,shirt,0.0037684275\r\n",
      "001,movie,0.0891871\r\n",
      "001,watch,0.026982259\r\n",
      "001,make,0.020209568\r\n",
      "001,wrong,0.016609019\r\n",
      "001,time,0.018557215\r\n",
      "001,funny,0.0075101038\r\n",
      "001,waste,0.011658727\r\n",
      "001,plot,0.008867379\r\n",
      "001,bore,0.011109356\r\n",
      "001,minute,0.006217682\r\n",
      "002,book,0.082376644\r\n",
      "002,story,0.030742362\r\n",
      "002,read,0.026288286\r\n",
      "002,character,0.01778436\r\n",
      "002,write,0.018424777\r\n",
      "002,find,0.017625522\r\n",
      "002,interest,0.014726332\r\n",
      "002,plot,0.012445922\r\n",
      "002,good,0.019640913\r\n",
      "002,bore,0.013027136\r\n",
      "003,film,0.04789476\r\n",
      "003,bad,0.023904858\r\n",
      "003,movie,0.023667585\r\n",
      "003,act,0.011379912\r\n",
      "003,star,0.010218274\r\n",
      "003,script,0.008100315\r\n",
      "003,make,0.013481576\r\n",
      "003,watch,0.011116439\r\n",
      "003,keanu,0.0064930655\r\n",
      "003,performance,0.0065185176\r\n",
      "004,work,0.061424877\r\n",
      "004,product,0.039028663\r\n",
      "004,great,0.015444886\r\n",
      "004,week,0.0121942\r\n",
      "004,stop,0.010744139\r\n",
      "004,day,0.009447135\r\n",
      "004,recommend,0.008850967\r\n",
      "004,battery,0.0072975117\r\n",
      "004,month,0.008529679\r\n",
      "004,warm,0.005031291\r\n",
      "005,work,0.047642704\r\n",
      "005,buy,0.03650683\r\n",
      "005,battery,0.018100744\r\n",
      "005,charge,0.016437955\r\n",
      "005,power,0.00931674\r\n",
      "005,month,0.011471893\r\n",
      "005,ibook,0.008112333\r\n",
      "005,adapter,0.0072650295\r\n",
      "005,turn,0.0076256157\r\n",
      "005,computer,0.008254448\r\n",
      "006,product,0.04387296\r\n",
      "006,quality,0.034586973\r\n",
      "006,poor,0.01320673\r\n",
      "006,sound,0.013718844\r\n",
      "006,picture,0.011741461\r\n",
      "006,wrong,0.013634796\r\n",
      "006,cheap,0.010068029\r\n",
      "006,video,0.009309592\r\n",
      "006,price,0.009771339\r\n",
      "006,pay,0.008338917\r\n",
      "007,toy,0.029507652\r\n",
      "007,play,0.03333662\r\n",
      "007,fall,0.019081116\r\n",
      "007,recommend,0.01419261\r\n",
      "007,love,0.014208696\r\n",
      "007,money,0.0158058\r\n",
      "007,week,0.010793178\r\n",
      "007,break,0.009478064\r\n",
      "007,year,0.011173023\r\n",
      "007,waste,0.011455448\r\n",
      "008,version,0.047566887\r\n",
      "008,original,0.028906595\r\n",
      "008,edition,0.013990366\r\n",
      "008,kindle,0.011575154\r\n",
      "008,miss,0.010661428\r\n",
      "008,amazon,0.011612214\r\n",
      "008,story,0.011087277\r\n",
      "008,release,0.008206131\r\n",
      "008,special,0.008052232\r\n",
      "008,great,0.011472537\r\n",
      "009,movie,0.07666788\r\n",
      "009,bad,0.061522327\r\n",
      "009,watch,0.031869102\r\n",
      "009,act,0.022932356\r\n",
      "009,film,0.01885905\r\n",
      "009,time,0.022179624\r\n",
      "009,waste,0.017343523\r\n",
      "009,worth,0.010653925\r\n",
      "009,plot,0.009688326\r\n",
      "009,script,0.0078074383\r\n",
      "010,album,0.074240826\r\n",
      "010,song,0.05625625\r\n",
      "010,music,0.022100465\r\n",
      "010,listen,0.018758254\r\n",
      "010,sound,0.020132013\r\n",
      "010,good,0.023599338\r\n",
      "010,hear,0.015135571\r\n",
      "010,band,0.01324048\r\n",
      "010,bad,0.019277286\r\n",
      "010,track,0.011071923\r\n",
      "011,diaper,0.10455835\r\n",
      "011,pamper,0.05836679\r\n",
      "011,baby,0.050552674\r\n",
      "011,spin-dry,0.040127117\r\n",
      "011,leak,0.035391156\r\n",
      "011,swaddlers,0.021988682\r\n",
      "011,cruiser,0.018013464\r\n",
      "011,huggies,0.017151086\r\n",
      "011,night,0.017087629\r\n",
      "011,change,0.015735213\r\n",
      "012,order,0.060182225\r\n",
      "012,item,0.042682853\r\n",
      "012,receive,0.04133922\r\n",
      "012,ship,0.02443934\r\n",
      "012,amazon,0.02626907\r\n",
      "012,month,0.018016374\r\n",
      "012,seller,0.015102321\r\n",
      "012,return,0.017870506\r\n",
      "012,product,0.020858211\r\n",
      "012,refund,0.012033874\r\n",
      "013,cd,0.09873658\r\n",
      "013,song,0.05302833\r\n",
      "013,clay,0.025479654\r\n",
      "013,buy,0.03917408\r\n",
      "013,disappoint,0.022931872\r\n",
      "013,music,0.019860195\r\n",
      "013,voice,0.016454669\r\n",
      "013,listen,0.01710911\r\n",
      "013,good,0.022979125\r\n",
      "013,hear,0.01186403\r\n",
      "014,book,0.2520323\r\n",
      "014,read,0.1061327\r\n",
      "014,bore,0.0320953\r\n",
      "014,write,0.022282641\r\n",
      "014,school,0.013378348\r\n",
      "014,page,0.014032812\r\n",
      "014,finish,0.012774598\r\n",
      "014,time,0.01943909\r\n",
      "014,story,0.015460486\r\n",
      "014,wrong,0.016374072\r\n",
      "015,dvd,0.085596114\r\n",
      "015,play,0.044678375\r\n",
      "015,player,0.03233141\r\n",
      "015,video,0.023185838\r\n",
      "015,watch,0.01742007\r\n",
      "015,quality,0.016842771\r\n",
      "015,sound,0.013007854\r\n",
      "015,picture,0.011502973\r\n",
      "015,purchase,0.013332147\r\n",
      "015,disc,0.01012748\r\n",
      "016,size,0.07328656\r\n",
      "016,fit,0.048807543\r\n",
      "016,small,0.03800164\r\n",
      "016,order,0.02758948\r\n",
      "016,large,0.020365717\r\n",
      "016,return,0.022821035\r\n",
      "016,ear,0.018189734\r\n",
      "016,wear,0.017069718\r\n",
      "016,big,0.013849742\r\n",
      "016,shoe,0.010150784\r\n",
      "017,game,0.1238484\r\n",
      "017,play,0.06278383\r\n",
      "017,graphic,0.010622689\r\n",
      "017,buy,0.026298828\r\n",
      "017,money,0.015152771\r\n",
      "017,nickelodeon,0.0064924\r\n",
      "017,toy,0.009074813\r\n",
      "017,level,0.006388615\r\n",
      "017,think,0.011427483\r\n",
      "017,bug,0.0060281665\r\n",
      "018,printer,0.08121262\r\n",
      "018,paper,0.07321005\r\n",
      "018,hp,0.04696072\r\n",
      "018,print,0.04208162\r\n",
      "018,problem,0.03149557\r\n",
      "018,fee,0.017291667\r\n",
      "018,jam,0.015800627\r\n",
      "018,time,0.021416537\r\n",
      "018,sheet,0.01292613\r\n",
      "018,year,0.015241767\r\n",
      "019,book,0.26473716\r\n",
      "019,buy,0.062373176\r\n",
      "019,review,0.023333069\r\n",
      "019,find,0.022104144\r\n",
      "019,read,0.024272142\r\n",
      "019,write,0.018618867\r\n",
      "019,page,0.0134164635\r\n",
      "019,save,0.013173116\r\n",
      "019,think,0.016073456\r\n",
      "019,worth,0.012455105\r\n"
     ]
    }
   ],
   "source": [
    "!cat topic-terms.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy Neutral Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_df = extract_df.head(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 12] Cannot allocate memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-16ad9f77aaf3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install nltk'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'punkt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'wordnet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36msystem_piped\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m   2259\u001b[0m         \u001b[0;31m# a non-None value would trigger :func:`sys.displayhook` calls.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2260\u001b[0m         \u001b[0;31m# Instead, we store the exit_code in user_ns.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2261\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_exit_code'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2263\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msystem_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/IPython/utils/_process_posix.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mchild\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpexpect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawnb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'-c'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Pexpect-U\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m                 \u001b[0mchild\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpexpect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'-c'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Vanilla Pexpect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m             \u001b[0mflush\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pexpect/pty_spawn.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, command, args, timeout, maxread, searchwindowsize, logfile, cwd, env, ignore_sighup, echo, preexec_fn, encoding, codec_errors, dimensions, use_poll)\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'<pexpect factory incomplete>'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spawn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreexec_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdimensions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_poll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_poll\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pexpect/pty_spawn.py\u001b[0m in \u001b[0;36m_spawn\u001b[0;34m(self, command, args, preexec_fn, dimensions)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m         self.ptyproc = self._spawnpty(self.args, env=self.env,\n\u001b[0;32m--> 303\u001b[0;31m                                      cwd=self.cwd, **kwargs)\n\u001b[0m\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mptyproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/pexpect/pty_spawn.py\u001b[0m in \u001b[0;36m_spawnpty\u001b[0;34m(self, args, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_spawnpty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;34m'''Spawn a pty and return an instance of PtyProcess.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mptyprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPtyProcess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/ptyprocess/ptyprocess.py\u001b[0m in \u001b[0;36mspawn\u001b[0;34m(cls, argv, cwd, env, echo, preexec_fn, dimensions)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_native_pty_fork\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;31m# Use internal fork_pty, for Solaris\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/pty.py\u001b[0m in \u001b[0;36mfork\u001b[0;34m()\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0mmaster_fd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslave_fd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopenpty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0mpid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mCHILD\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;31m# Establish a new session.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 12] Cannot allocate memory"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "import re\n",
    "token_pattern = re.compile(r\"(?u)\\b\\w\\w+\\b\")\n",
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, doc):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(doc) if len(t) >= 2 and re.match(\"[a-z].*\",t) \n",
    "                and re.match(token_pattern, t)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import shuffle\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "import csv\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.5.12\n",
      "  latest version: 4.7.11\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install -y scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing and counting, this may take a few minutes...\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 2000\n",
    "print('Tokenizing and counting, this may take a few minutes...')\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size: 2000\n",
      "Done. Time elapsed: 50.94s\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(input='content', analyzer='word', stop_words='english',\n",
    "                             tokenizer=LemmaTokenizer(), max_features=vocab_size, max_df=0.95, min_df=2)\n",
    "vectors = vectorizer.fit_transform(short_df)\n",
    "vocab_list = vectorizer.get_feature_names()\n",
    "print('vocab size:', len(vocab_list))\n",
    "\n",
    "# random shuffle\n",
    "idx = np.arange(vectors.shape[0])\n",
    "np.random.shuffle(idx)\n",
    "vectors = vectors[idx]\n",
    "\n",
    "print('Done. Time elapsed: {:.2f}s'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
